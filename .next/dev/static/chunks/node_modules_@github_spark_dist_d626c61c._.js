(globalThis.TURBOPACK || (globalThis.TURBOPACK = [])).push([typeof document === "object" ? document.currentScript : undefined,
"[project]/node_modules/@github/spark/dist/heartbeat-event-types-BmKuwNhb.js [client] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "E",
    ()=>EventType
]);
const EventType = {
    SPARK_RUNTIME_ERROR: 'sparkRuntimeError',
    SPARK_RUNTIME_PING: 'sparkRuntimePing',
    SPARK_RUNTIME_LOADED: 'sparkRuntimeLoaded',
    SPARK_VITE_WS_CONNECT: 'sparkViteWsConnect',
    SPARK_VITE_WS_DISCONNECT: 'sparkViteWsDisconnect',
    SPARK_VITE_ERROR: 'sparkViteError',
    SPARK_VITE_AFTER_UPDATE: 'sparkViteAfterUpdate',
    ROOT_ELEMENT_STATUS: 'rootElementStatus'
};
;
 //# sourceMappingURL=heartbeat-event-types-BmKuwNhb.js.map
}),
"[project]/node_modules/@github/spark/dist/kv-WMiiBMWU.js [client] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "K",
    ()=>KVClient,
    "a",
    ()=>KvEventType
]);
const __TURBOPACK__import$2e$meta__ = {
    get url () {
        return `file://${__turbopack_context__.P("node_modules/@github/spark/dist/kv-WMiiBMWU.js")}`;
    }
};
const KvEventType = {
    SPARK_KV_UPDATED: 'sparkKvUpdated',
    SPARK_KV_DELETED: 'sparkKvDeleted'
};
// This function allows us to send messages from the Spark back to the Workbench application.
// Specifically, we want to send updates about KV operations, to allow the Workbench
// to update its UI accordingly.
const sendEventToWorkbench = (message)=>{
    if (__TURBOPACK__import$2e$meta__.env.DEV) {
        window.parent.postMessage(message, '*');
    }
};
class KVClient {
    /**
    * Retrieves a list of all keys in the KV store.
    * @returns A list of all keys in the KV store, or an empty array if there are no keys.
    */ async getKeys() {
        // Fetching the root URL will return all keys in the KV store.
        const response = await fetch(BASE_KV_SERVICE_URL, {
            method: 'GET'
        });
        if (!response.ok) {
            const errorMessage = `Failed to fetch KV keys: ${response.statusText}`;
            return Promise.reject(new Error(errorMessage));
        }
        let json;
        try {
            json = await response.json();
        } catch (error) {
            const errorMessage = 'Failed to parse KV keys response';
            return Promise.reject(new Error(errorMessage));
        }
        if (!Array.isArray(json)) {
            const errorMessage = 'KV keys response is not an array';
            return Promise.reject(new Error(errorMessage));
        }
        return json;
    }
    /**
     * Retrieves all key-value pairs from the KV store.
     * @returns An object containing all key-value pairs, or an empty object if there are no keys.
     *
     * TODO: replace with batch request
     */ async getAll() {
        const keys = await this.getKeys();
        const result = {};
        // Fetch all values concurrently
        const values = await Promise.all(keys.map((key)=>this.getKey(key)));
        // Build the result object
        keys.forEach((key, index)=>{
            const value = values[index];
            if (value !== undefined) {
                result[key] = value;
            }
        });
        return result;
    }
    /**
     * Retrieves the value associated with the given key from the KV store.
     * @param key The key to retrieve.
     * @returns The value associated with the key, or undefined if not found.
     */ async getKey(key) {
        const response = await fetch(`${BASE_KV_SERVICE_URL}/${encodeURIComponent(key)}`, {
            method: 'GET',
            headers: {
                'Content-Type': `text/plain`
            }
        });
        if (!response.ok) {
            const errorMessage = `Failed to fetch KV key: ${response.statusText}`;
            if (response.status === 404) {
                // If the key does not exist, return undefined
                return undefined;
            }
            // For other errors, reject with an error message
            return Promise.reject(new Error(errorMessage));
        }
        const responseText = await response.text();
        // Extract the value from the response text.
        // Important to remember that even a simple string should be returned to us as a JSON-encoded value,
        // meaning that the parse should succeed.
        try {
            return JSON.parse(responseText);
        } catch (error) {
            const errorMessage = `Failed to parse KV key response`;
            return Promise.reject(new Error(errorMessage));
        }
    }
    /**
     * Retrieves the value associated with the given key from the KV store, while also setting it if it does not exist.
     * @param key The key to retrieve.
     * @param value The value to set if the key does not exist.
     * @returns The value associated with the key, whether it was retrieved or newly set.
     */ async getOrSetKey(key, value) {
        const existingValue = await this.getKey(key);
        if (existingValue !== undefined) {
            return existingValue;
        }
        const response = await fetch(`${BASE_KV_SERVICE_URL}/${encodeURIComponent(key)}`, {
            method: 'POST',
            headers: {
                'Content-Type': `text/plain`,
                'X-Spark-Initial': 'true'
            },
            body: JSON.stringify(value)
        });
        if (!response.ok) {
            const errorMessage = `Failed to set default value for key: ${response.statusText}`;
            return Promise.reject(new Error(errorMessage));
        }
        sendEventToWorkbench({
            type: KvEventType.SPARK_KV_UPDATED,
            payload: {
                key
            }
        });
        return value;
    }
    /**
     * Sets the value for the given key in the KV store.
     * @param key The key to set.
     * @param value The value to associate with the key.
     * @returns A promise that resolves when the operation is complete.
     */ async setKey(key, value) {
        const response = await fetch(`${BASE_KV_SERVICE_URL}/${encodeURIComponent(key)}`, {
            method: 'POST',
            headers: {
                'Content-Type': `text/plain`,
                'X-Spark-Initial': 'false'
            },
            body: JSON.stringify(value)
        });
        if (!response.ok) {
            const errorMessage = `Failed to set key: ${response.statusText}`;
            return Promise.reject(new Error(errorMessage));
        }
        sendEventToWorkbench({
            type: KvEventType.SPARK_KV_UPDATED,
            payload: {
                key,
                value: JSON.stringify(value)
            }
        });
    }
    /**
     * Deletes the value associated with the given key from the KV store.
     * @param key The key to delete from the KV store.
     */ async deleteKey(key) {
        await fetch(`${BASE_KV_SERVICE_URL}/${encodeURIComponent(key)}`, {
            method: 'DELETE'
        });
        sendEventToWorkbench({
            type: KvEventType.SPARK_KV_DELETED,
            payload: {
                key
            }
        });
    }
}
;
 //# sourceMappingURL=kv-WMiiBMWU.js.map
}),
"[project]/node_modules/@github/spark/dist/llm.js [client] (ecmascript)", ((__turbopack_context__) => {
"use strict";

// Earlier versions of our generation recommended models without the prefix
// that GH Models wants. For compatibility, correct those that were on the list explicitly.
__turbopack_context__.s([
    "llm",
    ()=>llm,
    "llmPrompt",
    ()=>llmPrompt
]);
const MODEL_FIXES = {
    'ai21-jamba-instruct': 'ai21-labs/ai21-jamba-instruct',
    'cohere-command-r-plus': 'cohere/cohere-command-r-plus',
    'cohere-command-r': 'cohere/cohere-command-r',
    'gpt-4o-mini': 'openai/gpt-4o-mini',
    'gpt-4o': 'openai/gpt-4o',
    'meta-llama-3.1-405b-instruct': 'meta/meta-llama-3.1-405b-instruct',
    'meta-llama-3.1-70b-instruct': 'meta/meta-llama-3.1-70b-instruct',
    'meta-llama-3.1-8b-instruct': 'meta/meta-llama-3.1-8b-instruct',
    'meta-llama-3-70b-instruct': 'meta/meta-llama-3-70b-instruct',
    'meta-llama-3-8b-instruct': 'meta/meta-llama-3-8b-instruct',
    'mistral-large-2407': 'mistral-ai/mistral-large-2407',
    'mistral-large': 'mistral-ai/mistral-large',
    'mistral-nemo': 'mistral-ai/mistral-nemo',
    'mistral-small': 'mistral-ai/mistral-small',
    'phi-3-medium-128K-instruct': 'microsoft/phi-3-medium-128K-instruct',
    'phi-3-medium-4K-instruct': 'microsoft/phi-3-medium-4K-instruct',
    'phi-3-mini-128K-instruct': 'microsoft/phi-3-mini-128K-instruct',
    'phi-3-mini-4K-instruct': 'microsoft/phi-3-mini-4K-instruct',
    'phi-3-small-128K-instruct': 'microsoft/phi-3-small-128K-instruct',
    'phi-3-small-8K-instruct': 'microsoft/phi-3-small-8K-instruct'
};
const fixModelName = (modelName)=>{
    if (!modelName) return 'openai/gpt-4o';
    return MODEL_FIXES[modelName] || modelName;
};
async function llm(prompt, modelName, jsonMode) {
    const tidiedModelName = fixModelName(modelName);
    const response_format = {
        type: jsonMode ? 'json_object' : 'text'
    };
    const body = {
        messages: [
            {
                role: 'system',
                content: 'You are a helpful assistant.'
            },
            {
                role: 'user',
                content: prompt
            }
        ],
        temperature: 1.0,
        top_p: 1.0,
        max_tokens: 1000,
        model: tidiedModelName,
        response_format
    };
    const response = await fetch('/_spark/llm', {
        method: 'POST',
        body: JSON.stringify(body),
        headers: {
            'Content-Type': `application/json`
        }
    });
    if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`LLM request failed: ${response.status} ${response.statusText} - ${errorText}`);
    }
    const data = await response.json();
    const content = data.choices[0].message.content;
    return content;
}
function llmPrompt(strings, ...values) {
    return strings.reduce((result, str, i)=>result + str + (values[i] || ''), '');
}
;
 //# sourceMappingURL=llm.js.map
}),
"[project]/node_modules/@github/spark/dist/spark.js [client] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$heartbeat$2d$event$2d$types$2d$BmKuwNhb$2e$js__$5b$client$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@github/spark/dist/heartbeat-event-types-BmKuwNhb.js [client] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$kv$2d$WMiiBMWU$2e$js__$5b$client$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@github/spark/dist/kv-WMiiBMWU.js [client] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$llm$2e$js__$5b$client$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@github/spark/dist/llm.js [client] (ecmascript)");
;
;
;
let cachedUser = null;
async function fetchUser() {
    try {
        if (cachedUser) {
            return cachedUser;
        }
        const response = await fetch('/_spark/user');
        cachedUser = await response.json();
        return cachedUser;
    } catch (error) {
        console.error('Failed to fetch user data:', error);
        return null;
    }
}
const payload = {
    url: window?.location?.href,
    load_ms: window?.performance?.now()
};
window.parent.postMessage({
    type: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$heartbeat$2d$event$2d$types$2d$BmKuwNhb$2e$js__$5b$client$5d$__$28$ecmascript$29$__["E"].SPARK_RUNTIME_LOADED,
    payload
}, '*');
fetch('/_spark/loaded', {
    method: 'POST',
    headers: {
        'Content-Type': `application/json`
    },
    body: JSON.stringify(payload)
});
const kv = {
    keys: async ()=>{
        const client = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$kv$2d$WMiiBMWU$2e$js__$5b$client$5d$__$28$ecmascript$29$__["K"]();
        return client.getKeys();
    },
    get: async (key)=>{
        const client = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$kv$2d$WMiiBMWU$2e$js__$5b$client$5d$__$28$ecmascript$29$__["K"]();
        return client.getKey(key);
    },
    set: async (key, value)=>{
        const client = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$kv$2d$WMiiBMWU$2e$js__$5b$client$5d$__$28$ecmascript$29$__["K"]();
        return client.setKey(key, value);
    },
    delete: async (key)=>{
        const client = new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$kv$2d$WMiiBMWU$2e$js__$5b$client$5d$__$28$ecmascript$29$__["K"]();
        return client.deleteKey(key);
    }
};
window.spark = {
    llmPrompt: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$llm$2e$js__$5b$client$5d$__$28$ecmascript$29$__["llmPrompt"],
    llm: __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$github$2f$spark$2f$dist$2f$llm$2e$js__$5b$client$5d$__$28$ecmascript$29$__["llm"],
    user: fetchUser,
    kv
}; //# sourceMappingURL=spark.js.map
}),
]);

//# sourceMappingURL=node_modules_%40github_spark_dist_d626c61c._.js.map